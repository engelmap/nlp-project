{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba7deb1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Paul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "import string\n",
    "from string import digits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, matthews_corrcoef, classification_report\n",
    "from sklearn.metrics import cohen_kappa_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "en_core = spacy.load('en_core_web_sm')\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2833ddde",
   "metadata": {},
   "source": [
    "## NLP Project by Johanna Dahlke, Dmitry Degtyar, Daniel Neufeld, Paul Engelmann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254367b7",
   "metadata": {},
   "source": [
    "## Original dataset read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3472ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_readin():\n",
    "    data = pd.read_csv(\"tweet_emotions.csv\")\n",
    "    count = 0\n",
    "    for index, sent in enumerate(data.sentiment):\n",
    "        if sent == \"fun\" or sent == \"enthusiasm\" or sent == \"love\" or sent == \"happiness\" or sent ==\"relief\":\n",
    "            data.loc[index,['sentiment']] = \"positive\"\n",
    "        elif sent == \"hate\" or sent == \"anger\" or sent == \"empty\" or sent == \"worry\" or sent == \"sadness\" or sent == \"boredom\":\n",
    "            data.loc[index,['sentiment']] = \"negative\"\n",
    "        else:\n",
    "            #if count % 6 != 0:\n",
    "            data.drop([index], axis=0, inplace=True)\n",
    "\n",
    "    data.to_csv('tweet_emotions_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92d6997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ternary_readin():\n",
    "    data = pd.read_csv(\"tweet_emotions.csv\")\n",
    "    count = 0\n",
    "    for index, sent in enumerate(data.sentiment):\n",
    "        if sent == \"fun\" or sent == \"enthusiasm\" or sent == \"love\" or sent == \"happiness\" or sent ==\"relief\":\n",
    "            data.loc[index,['sentiment']] = \"positive\"\n",
    "        elif sent == \"hate\" or sent == \"anger\" or sent == \"empty\" or sent == \"worry\" or sent == \"sadness\" or sent == \"boredom\":\n",
    "            data.loc[index,['sentiment']] = \"negative\"\n",
    "        elif sent == \"surprise\":\n",
    "            data.drop([index], axis=0, inplace=True)\n",
    "    data.to_csv('tweet_emotions_three_classes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef03b1cc",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2fbabaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(line_text):\n",
    "    line_text_without_punct = re.sub(r'[^\\w\\s]', '', line_text)\n",
    "    return line_text_without_punct\n",
    "\n",
    "\n",
    "def remove_numbers(line_text):\n",
    "    table = str.maketrans('', '', digits)\n",
    "    line_text_without_nums = line_text.translate(table)\n",
    "    return line_text_without_nums\n",
    "\n",
    "def remove_url(line_text):\n",
    "    #(https?:\\/\\/) matches http:// or https://\n",
    "    #(\\s)* optional whitespaces\n",
    "    #(www\\.)? optionally matches www.\n",
    "    # (\\s)* optionally matches whitespaces\n",
    "    #'((\\w|\\s)+\\.)* matches 0 or more of one or more word characters followed by a period\n",
    "    #([\\w\\-\\s]+\\/)* matches 0 or more of one or more words(or a dash or a space) followed by '\\'\n",
    "    #([\\w\\-]+) any remaining path at the end of the url followed by an optional ending\n",
    "    #((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)* matches ending query params (even with white spaces,etc)\n",
    "\n",
    "    line_text_without_url = re.sub(r'(https?:\\/\\/)(\\s)*(www\\.)?(\\s)*((\\w|\\s)+\\.)*([\\w\\-\\s]+\\/)*([\\w\\-]+)((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)*', '', line_text)\n",
    "    return line_text_without_url\n",
    "\n",
    "def remove_username(line_text):\n",
    "    line_text_without_username = re.sub(\"([@#][A-Za-z0-9_]+)|(\\w+:\\/\\/\\S+)\",'', line_text)\n",
    "    return line_text_without_username\n",
    "\n",
    "def remove_stopwords(line_text):\n",
    "    line_text_without_stopwords = ' '.join([word for word in line_text.split()\n",
    "                                           if word not in (stopwords.words('english'))])\n",
    "    return line_text_without_stopwords\n",
    "\n",
    "def translate_abbreviations(line_text):\n",
    "    text_list = line_text.split()\n",
    "    with open(\"slang_abbreviations.txt\", 'r') as my_csv_file:\n",
    "        data_from_file = csv.reader(my_csv_file, delimiter=\"=\")\n",
    "        for index, _str in enumerate(text_list):\n",
    "            _str = re.sub('[^a-zA-Z0-9-_.]', '', _str)\n",
    "            for row in data_from_file:\n",
    "                if _str.upper() == row[0]:\n",
    "                    text_list[index] = row[1]\n",
    "    final_string = ' '.join(text_list)\n",
    "    return final_string\n",
    "\n",
    "def remove_hashtags(line_text):\n",
    "    line_text_without_hashtags = line_text.replace('#','')\n",
    "    return line_text_without_hashtags\n",
    "\n",
    "def lemmatizing(line_text):\n",
    "    final_string = \" \".join([word.lemma_ for word in en_core(line_text)])\n",
    "    return final_string\n",
    "\n",
    "def clean_line(line_text):\n",
    "    text_zero = remove_numbers(line_text)\n",
    "    text_one = remove_username(text_zero)\n",
    "    text_two = remove_url(text_one)\n",
    "    text_three = remove_punctuation(text_two)\n",
    "    text_four = remove_hashtags(text_three)\n",
    "    text_five = remove_stopwords(text_four)\n",
    "    text_six = translate_abbreviations(text_five)\n",
    "    text_final = lemmatizing(text_six)\n",
    "    return text_final.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6334886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_binary_sentiment(corpus):\n",
    "    doc = nlp(corpus)\n",
    "    polarity = doc._.blob.polarity\n",
    "    subject = doc._.blob.subjectivity \n",
    "    if polarity > 0:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\"\n",
    "    \n",
    "def extract_ternary_sentiment(corpus):\n",
    "    doc = nlp(corpus)\n",
    "    polarity = doc._.blob.polarity\n",
    "    subject = doc._.blob.subjectivity \n",
    "    if polarity >= -0.01 and polarity <= 0.01:\n",
    "        return \"neutral\"\n",
    "    elif polarity > 0.1:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76a3178",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99076224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curves_display(data_choice, vect_choice, classifiers, X, y, ylim=(0.5, 1.01), cv=None, n_jobs=None, \n",
    "                        train_sizes=np.linspace(0.1, 1.0, 5)):\n",
    "    \n",
    "    size = len(classifiers)\n",
    "    for clf in classifiers:\n",
    "        if data_choice == \"complete\":\n",
    "            ylim = (0.1, 1.01)\n",
    "        else:\n",
    "            ylim = (0.1, 1.01)\n",
    "        plot_learning_curve(data_choice, vect_choice, clf, X, y, ylim, cv, n_jobs, train_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "322298c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_display(data_choice, vect_choice, classifiers, X, y):\n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5, random_state=42, shuffle=True)\n",
    "    \n",
    "    results = {}\n",
    "    for clf in classifiers:\n",
    "        clf_name = type(clf).__name__\n",
    "        results[clf_name] = calc_metrics(data_choice, vect_choice, clf, X_train, y_train, X_valid, y_valid)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95b7eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(data_choice, vect_choice, clf, X_train, y_train, X_valid, y_valid):\n",
    "    figsize = ()\n",
    "    if data_choice == \"complete\":\n",
    "        figsize=(15, 12)\n",
    "    else:\n",
    "        figsize=(10, 6)\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    clf_name = type(clf).__name__\n",
    "    axes.set_title(f'{clf_name}, {data_choice.capitalize()} dataset, {vect_choice.capitalize()}')\n",
    "    results = {}\n",
    "\n",
    "    print(f\"Started training: {clf_name}\")\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Finished training: {clf_name}\")\n",
    "\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "\n",
    "    cm = ConfusionMatrixDisplay.from_predictions(y_valid, y_pred)\n",
    "    \n",
    "    axes.xaxis.label.set_color('white')\n",
    "    axes.yaxis.label.set_color('white')\n",
    "    axes.title.set_color('white')\n",
    "    axes.tick_params(axis='x', colors='white')\n",
    "    axes.tick_params(axis='y', colors='white')\n",
    "    \n",
    "    cm.plot(ax=axes)\n",
    "    results[\"accuracy\"] = balanced_accuracy_score(y_valid, y_pred)\n",
    "\n",
    "    all_scores = precision_recall_fscore_support(y_valid, y_pred, pos_label=\"positive\", average=\"weighted\")#macro, micro or weighted?\n",
    "    results[\"precision\"] = all_scores[0] \n",
    "    results[\"recall\"] = all_scores[1] \n",
    "    results[\"f1\"] = all_scores[2] \n",
    "\n",
    "    results[\"matthew_coeff\"] = matthews_corrcoef(y_valid, y_pred)\n",
    "    results[\"cohen_kappa\"] = cohen_kappa_score(y_valid, y_pred)   \n",
    "    \n",
    "    #fig.patch.set_facecolor('white')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'confusion_matrix_{clf_name}_{data_choice}_{vect_choice}.png')   \n",
    "    print(f'Saved to confusion_matrix_{clf_name}_{data_choice}_{vect_choice}.png')\n",
    "    \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c2b76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(data_choice, vect_choice, clf, X, y, ylim=(0.5, 1.01), cv=None, n_jobs=None, \n",
    "                        train_sizes=np.linspace(0.1, 1.0, 5)):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_xlabel(\"Training examples\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "\n",
    "    clf_name = type(clf).__name__\n",
    "    ax.set_title(f\"{clf_name}, {data_choice.capitalize()} dataset, {vect_choice.capitalize()}\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(clf, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)                                                                                                           \n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    ax.grid()\n",
    "    ax.fill_between(\n",
    "        train_sizes,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"r\",\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        train_sizes,\n",
    "        test_scores_mean - test_scores_std,\n",
    "        test_scores_mean + test_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"g\",\n",
    "    )\n",
    "    \n",
    "    ax.xaxis.label.set_color('white')\n",
    "    ax.yaxis.label.set_color('white')\n",
    "    ax.title.set_color('white')\n",
    "    ax.tick_params(axis='x', colors='white')\n",
    "    ax.tick_params(axis='y', colors='white')\n",
    "    \n",
    "    ax.plot(train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\")\n",
    "    ax.plot(train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    \n",
    "    \n",
    "    fig.savefig(f'learning_curve_{clf_name}_{data_choice}_{vect_choice}.png')\n",
    "    print(f'Saved to learning_curve_{clf_name}_{data_choice}_{vect_choice}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633a19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_df():\n",
    "    return pd.read_csv(\"tweet_emotions_binary_cleaned.csv\")\n",
    "\n",
    "def get_ternary_df():\n",
    "    return pd.read_csv(\"tweet_emotions_three_classes_cleaned.csv\")\n",
    "\n",
    "def get_complete_df():\n",
    "    return pd.read_csv(\"tweet_emotions_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc538711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the models for the learning curves and metrics\n",
    "def train_models(classifiers, data_choice=\"binary\", vect_choice=\"tfidf\", text=\"text\", labels=\"sentiment\"):\n",
    "    df = None\n",
    "    \n",
    "    if data_choice == \"binary\":\n",
    "        df = get_binary_df()\n",
    "    elif data_choice == \"ternary\":\n",
    "        df = get_ternary_df()\n",
    "    elif data_choice == \"complete\":\n",
    "        df = get_complete_df()\n",
    "        labels = \"sentiment\"\n",
    "    else:\n",
    "        df = get_binary_df()\n",
    "    \n",
    "    df = remove_empty_rows(df)\n",
    "    \n",
    "    X = None\n",
    "    if vect_choice == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectorizer.fit(df[\"cleaned_content\"])\n",
    "        X = vectorizer.transform(df[text])\n",
    "        print(\"Amount of features: \", len(vectorizer.get_feature_names_out()))\n",
    "        print(\"Features: \", vectorizer.get_feature_names_out())\n",
    "    elif vect_choice == \"spacy\":\n",
    "        X = [nlp(text).vector for text in df[\"cleaned_content\"]]\n",
    "    \n",
    "    y = df[labels]\n",
    "\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    learning_curves_display(data_choice, vect_choice, classifiers, X, y, cv=cv, n_jobs=4)\n",
    "    \n",
    "    results = metrics_display(data_choice, vect_choice, classifiers, X, y)\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f764539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar plot for accuracy and f1 comparison\n",
    "def create_bar_plot(data_choice, vect_choices, score_type):\n",
    "    fig, ax = plt.subplots(figsize=(8 , 4))\n",
    "    \n",
    "    scores = {}\n",
    "    colors = {\"tfidf\": \"navy\", \"spacy\": \"lightblue\"}\n",
    "    min_ax = 10000000000\n",
    "    max_ax = 0\n",
    "    \n",
    "    for vect_choice in vect_choices:\n",
    "        df = pd.read_csv(f\"{data_choice}_{vect_choice}_results_raw.csv\", index_col=0)\n",
    "        scores[vect_choice] = df.loc[score_type] # acc1 for each clf\n",
    "        min_ax = min(min_ax, min(df.loc[score_type]))\n",
    "        max_ax = max(max_ax, max(df.loc[score_type]))\n",
    "        \n",
    "    df = pd.DataFrame.from_dict(scores)\n",
    "    ax.set_ylim((min_ax-0.01, max_ax+0.03))\n",
    "    ax.set_title(f'{score_type.capitalize()} Comparison, {data_choice.capitalize()} Dataset')\n",
    "    ax.set_ylabel(f'{score_type.capitalize()} Scores')\n",
    "    ax.xaxis.label.set_color('white')\n",
    "    ax.yaxis.label.set_color('white')\n",
    "    ax.title.set_color('white')\n",
    "    ax.tick_params(axis='x', colors='white')\n",
    "    ax.tick_params(axis='y', colors='white') \n",
    "    df.plot.bar(ax=ax)\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax = plt.gca()\n",
    "    for p in ax.patches[0:]:\n",
    "        plt.gca().text(p.get_x() + p.get_width()/2, p.get_height()+0.0025, str(round(p.get_height(), 2)), \n",
    "                 ha='center', va='baseline', rotation=0 ,color='black', fontsize=10)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'{score_type}_scores_comparison_{data_choice}.png')\n",
    "    print(f'Saved to {score_type}_scores_comparison_{data_choice}.png')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a07e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if any rows were completely empty after cleaning them, this removes them\n",
    "def remove_empty_rows(df, text=\"cleaned_content\", labels=\"sentiment\"):\n",
    "    df[text].replace(\"\", np.nan, inplace=True)\n",
    "    df.dropna(subset=[text], inplace=True)\n",
    "    df[labels].replace(\"\", np.nan, inplace=True)\n",
    "    df.dropna(subset=[labels], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df2f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot matthew correlation table\n",
    "def plot_matthew(data_choice, vect_choices, score_type=\"matthew_coeff\"):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    fig.patch.set_visible(False)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    score_names = {}\n",
    "    scores = {}\n",
    "    \n",
    "    score_names[\"matthew_coeff\"] = \"Matthews Correlation Coefficient\"\n",
    "    \n",
    "    for vect_choice in vect_choices:\n",
    "        df = pd.read_csv(f\"{data_choice}_{vect_choice}_results_raw.csv\", index_col=0)\n",
    "        scores[vect_choice] = df.loc[score_type]\n",
    "    df = pd.DataFrame.from_dict(scores)\n",
    "    df = df.round(2)\n",
    "    df = df.transpose()\n",
    "    names = (\"SVM\", \"RF\", \"MLP\")\n",
    "    ax.set_title(score_names[score_type], y=0.575)\n",
    "    ax.title.set_color('white')\n",
    "    ax.table(cellText=df.values, colLabels=names, rowLabels=vect_choices, loc='center', cellLoc=\"center\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'{data_choice}_matthews_corr.png')\n",
    "    print(f'Saved to {data_choice}_matthews_corr.png')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "# plots the accuracy, precision, recall and f1 score as a table\n",
    "def plot_f1(data_choice, vect_choices):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(7, 5))\n",
    "    fig.patch.set_visible(False)\n",
    "    \n",
    "    \n",
    "    score_names = {}\n",
    "    scores = {}\n",
    "    \n",
    "    score_names[\"precision\"] = \"Precision\"\n",
    "    score_names[\"accuracy\"] = \"Accuracy\"\n",
    "    score_names[\"recall\"] = \"Recall\"\n",
    "    score_names[\"f1\"] = \"F1 Score\"\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(vect_choices)):\n",
    "        vect_choice = vect_choices[i]\n",
    "        ax[i].axis('off')\n",
    "        df = pd.read_csv(f\"{data_choice}_{vect_choice}_results_raw.csv\", index_col=0)\n",
    "        df = df.iloc[:4]\n",
    "        df = df.round(2)\n",
    "        names = (\"SVM\", \"RF\", \"MLP\")\n",
    "        rowLabels = (\"Accuracy\", \"Precision\", \"Recall\", \"F1\")\n",
    "        ax[i].set_title(f\"{vect_choice.capitalize() }\", y=0.61)\n",
    "        ax[i].title.set_color('white')\n",
    "        ax[i].table(cellText=df.values, colLabels=names, loc='center', rowLabels=rowLabels, cellLoc=\"center\")\n",
    "      \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'{data_choice}_prec_recall_f1.png')\n",
    "    print(f'Saved to {data_choice}_prec_recall_f1.png')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31e0a761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleans all data with our previously defined functions\n",
    "#has already been done with the included csv's, so no need to further clean. \n",
    "#this is just here for completeness sake\n",
    "def clean_all():\n",
    "    df_multiple = pd.read_csv(\"tweet_emotions.csv\")\n",
    "    df_binary = pd.read_csv(\"tweet_emotions_binary.csv\")\n",
    "    for index, row in df_binary.iterrows():\n",
    "            df_binary.at[index,'sentiment'] = extract_binary_sentiment(df_binary.at[index, \"content\"])\n",
    "    \n",
    "    df_three_classes = pd.read_csv(\"tweet_emotions_three_classes.csv\")\n",
    "    for index, row in df_three_classes.iterrows():\n",
    "            df_three_classes.at[index,'sentiment'] = extract_ternary_sentiment(df_three_classes.at[index, \"content\"])\n",
    "    \n",
    "    df_multiple['cleaned_content'] = df_multiple.content.apply(clean_line)\n",
    "    df_multiple = remove_empty_rows(df_multiple)\n",
    "    \n",
    "    df_binary['cleaned_content'] = df_binary.content.apply(clean_line)\n",
    "    df_binary = df_binary.loc[:, ~df_binary.columns.str.contains('^Unnamed')]\n",
    "    df_binary = remove_empty_rows(df_binary)\n",
    "    \n",
    "    df_three_classes['cleaned_content'] = df_three_classes.content.apply(clean_line)\n",
    "    df_three_classes = df_three_classes.loc[:, ~df_three_classes.columns.str.contains('^Unnamed')]\n",
    "    df_three_classes = remove_empty_rows(df_three_classes)\n",
    "    \n",
    "    \n",
    "    df_binary.to_csv('tweet_emotions_binary_cleaned.csv')\n",
    "    df_three_classes.to_csv('tweet_emotions_three_classes_cleaned.csv')\n",
    "    df_multiple.to_csv('tweet_emotions_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0b1f14b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifiers = [svm.LinearSVC(), RandomForestClassifier(), MLPClassifier(max_iter=50, early_stopping=True)]\n",
    "data_choices = [\"binary\", \"ternary\", \"complete\"]\n",
    "vect_choices = [\"tfidf\", \"spacy\"] \n",
    "\n",
    "for data_choice in data_choices:\n",
    "    for vect_choice in vect_choices:\n",
    "        df_results = train_models(classifiers, data_choice, vect_choice, text=\"cleaned_content\", labels=\"sentiment\")\n",
    "        df_results.to_csv(f\"{data_choice}_{vect_choice}_results_raw.csv\")\n",
    "          \n",
    "    create_bar_plot(data_choice, vect_choices, \"f1\")\n",
    "    create_bar_plot(data_choice, vect_choices, \"accuracy\")\n",
    "        \n",
    "    plot_matthew(data_choice, vect_choices, \"matthew_coeff\")\n",
    "    plot_f1(data_choice, vect_choices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4659a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
