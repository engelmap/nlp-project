{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dmitry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "nlp_lg = spacy.load('en_core_web_lg')\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neutral', 'surprise', 'enthusiasm', 'fun', 'anger', 'empty', 'sadness', 'hate', 'boredom', 'relief', 'worry', 'happiness', 'love'}\n",
      "2187\n",
      "16063\n",
      "13112\n"
     ]
    }
   ],
   "source": [
    "#binary\n",
    "data = []\n",
    "with open('tweet_emotions.csv', mode ='r')as file:\n",
    "    readed = csv.reader(file)\n",
    "    count = False\n",
    "    for line in readed:\n",
    "        if count:\n",
    "            data.append(line)\n",
    "        else:\n",
    "            count=True\n",
    "    positive = []\n",
    "    negative = []\n",
    "    print(set([x[1] for x in data]))\n",
    "    print(len([x for x in data if x[1]==\"surprise\"]))\n",
    "\n",
    "    count = 0\n",
    "    for x in data:\n",
    "        if x[1] == \"fun\" or x[1] == \"enthusiasm\" or x[1] == \"love\" or x[1] == \"happiness\" or x[1] ==\"relief\":\n",
    "            positive.append(x)\n",
    "        if x[1] == \"hate\" or x[1] == \"anger\" or x[1] == \"empty\" or x[1] == \"worry\" or x[1] == \"sadness\" or x[1] == \"boredom\":\n",
    "            #if count % 6 != 0:\n",
    "            negative.append(x)\n",
    "        count +=1\n",
    "    print(len(negative))\n",
    "    print(len(positive))\n",
    "    file_pos = open(r'positive.csv', 'w+', newline ='')\n",
    "    file_neg = open(r'negative.csv', 'w+', newline ='')\n",
    "    with file_pos:\n",
    "        write = csv.writer(file_pos)\n",
    "        write.writerows(positive)\n",
    "    with file_neg:\n",
    "        write=csv.writer(file_neg)\n",
    "        write.writerows(negative)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'C2'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [103]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m df_neg \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnegative.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m df_pos \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpositive.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mdf_pos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mC2\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/venv/lib/python3.8/site-packages/pandas/core/generic.py:5575\u001B[0m, in \u001B[0;36mNDFrame.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   5568\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   5569\u001B[0m     name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_names_set\n\u001B[1;32m   5570\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metadata\n\u001B[1;32m   5571\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessors\n\u001B[1;32m   5572\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info_axis\u001B[38;5;241m.\u001B[39m_can_hold_identifiers_and_holds_name(name)\n\u001B[1;32m   5573\u001B[0m ):\n\u001B[1;32m   5574\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m[name]\n\u001B[0;32m-> 5575\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mobject\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'C2'"
     ]
    }
   ],
   "source": [
    "df_neg = pd.read_csv('negative.csv')\n",
    "df_pos = pd.read_csv('positive.csv')\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data cleaning functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "\n",
    "def remove_punctuation(line_text):\n",
    "    line_text_without_punct = re.sub(r'[^\\w\\s]', '', line_text)\n",
    "    return line_text_without_punct\n",
    "\n",
    "\n",
    "def remove_numbers(line_text):\n",
    "    line_text_without_nums = re.sub(r' \\d+', '', line_text)\n",
    "    return line_text_without_nums\n",
    "\n",
    "def remove_url(line_text):\n",
    "    #(https?:\\/\\/) matches http:// or https://\n",
    "    #(\\s)* optional whitespaces\n",
    "    #(www\\.)? optionally matches www.\n",
    "    # (\\s)* optionally matches whitespaces\n",
    "    #'((\\w|\\s)+\\.)* matches 0 or more of one or more word characters followed by a period\n",
    "    #([\\w\\-\\s]+\\/)* matches 0 or more of one or more words(or a dash or a space) followed by '\\'\n",
    "    #([\\w\\-]+) any remaining path at the end of the url followed by an optional ending\n",
    "    #((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)* matches ending query params (even with white spaces,etc)\n",
    "\n",
    "    line_text_without_url = re.sub(r'(https?:\\/\\/)(\\s)*(www\\.)?(\\s)*((\\w|\\s)+\\.)*([\\w\\-\\s]+\\/)*([\\w\\-]+)((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)*', '', line_text)\n",
    "    return line_text_without_url\n",
    "\n",
    "def remove_username(line_text):\n",
    "    line_text_without_username = re.sub(\"([@#][A-Za-z0-9_]+)|(\\w+:\\/\\/\\S+)\",'', line_text)\n",
    "    return line_text_without_username\n",
    "\n",
    "def remove_stopwords(line_text):\n",
    "    line_text_without_stopwords = ' '.join([word for word in line_text.split()\n",
    "                                           if word not in (stopwords.words('english'))])\n",
    "    return line_text_without_stopwords\n",
    "\n",
    "def translate_abbreviations(line_text):\n",
    "    text_list = line_text.split()\n",
    "    with open(\"slang_abbreviations.txt\", 'r') as my_csv_file:\n",
    "        data_from_file = csv.reader(my_csv_file, delimiter=\"=\")\n",
    "        for index, _str in enumerate(text_list):\n",
    "            _str = re.sub('[^a-zA-Z0-9-_.]', '', _str)\n",
    "            for row in data_from_file:\n",
    "                if _str.upper() == row[0]:\n",
    "                    text_list[index] = row[1]\n",
    "    final_string = ' '.join(text_list)\n",
    "    return final_string\n",
    "\n",
    "def remove_hashtags(line_text):\n",
    "    line_text_without_hashtags = line_text.replace('#','')\n",
    "    return line_text_without_hashtags\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "def stemming(line_text):\n",
    "    text_list = [ps.stem(word) for word in line_text.split()]\n",
    "    final_string = ' '.join(text_list)\n",
    "    return final_string\n",
    "\n",
    "\n",
    "def clean_line(line_text):\n",
    "    text_zero = remove_username(line_text)\n",
    "    text_one = remove_url(text_zero)\n",
    "    text_two = remove_punctuation(text_one)\n",
    "    text_three = remove_hashtags(text_two)\n",
    "    text_four = remove_numbers(text_three)\n",
    "    text_five = remove_stopwords(text_four)\n",
    "    text_six = translate_abbreviations(text_five)\n",
    "    text_final = stemming(text_six)\n",
    "    return text_final\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cleaning the text and saving cleaned version to new column 'cleaned_content'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tweet_emotions.csv\")\n",
    "df['cleaned_content'] = df.content.apply(clean_line)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Saving cleaned Dataframe to scv for future"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "df.to_csv('tweet_emotions_cleaned.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "         tweet_id   sentiment  \\\n0      1956967341       empty   \n1      1956967666     sadness   \n2      1956967696     sadness   \n3      1956967789  enthusiasm   \n4      1956968416     neutral   \n...           ...         ...   \n39995  1753918954     neutral   \n39996  1753919001        love   \n39997  1753919005        love   \n39998  1753919043   happiness   \n39999  1753919049        love   \n\n                                                 content  \\\n0      @tiffanylue i know  i was listenin to bad habi...   \n1      Layin n bed with a headache  ughhhh...waitin o...   \n2                    Funeral ceremony...gloomy friday...   \n3                   wants to hang out with friends SOON!   \n4      @dannycastillo We want to trade with someone w...   \n...                                                  ...   \n39995                                   @JohnLloydTaylor   \n39996                     Happy Mothers Day  All my love   \n39997  Happy Mother's Day to all the mommies out ther...   \n39998  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...   \n39999  @mopedronin bullet train from tokyo    the gf ...   \n\n                                         cleaned_content  \n0      know listenin bad habit earlier start freakin ...  \n1                  layin n bed headach ughhhhwaitin call  \n2                            funer ceremonygloomi friday  \n3                                  want hang friend soon  \n4                we want trade someon houston ticket one  \n...                                                  ...  \n39995                                                     \n39996                          happi mother day all love  \n39997  happi mother day mommi woman man long your mom...  \n39998  wassup beauti follow me peep out my new hit si...  \n39999  bullet train tokyo gf visit japan sinc thursda...  \n\n[40000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>sentiment</th>\n      <th>content</th>\n      <th>cleaned_content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1956967341</td>\n      <td>empty</td>\n      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n      <td>know listenin bad habit earlier start freakin ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1956967666</td>\n      <td>sadness</td>\n      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n      <td>layin n bed headach ughhhhwaitin call</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1956967696</td>\n      <td>sadness</td>\n      <td>Funeral ceremony...gloomy friday...</td>\n      <td>funer ceremonygloomi friday</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1956967789</td>\n      <td>enthusiasm</td>\n      <td>wants to hang out with friends SOON!</td>\n      <td>want hang friend soon</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1956968416</td>\n      <td>neutral</td>\n      <td>@dannycastillo We want to trade with someone w...</td>\n      <td>we want trade someon houston ticket one</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39995</th>\n      <td>1753918954</td>\n      <td>neutral</td>\n      <td>@JohnLloydTaylor</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>39996</th>\n      <td>1753919001</td>\n      <td>love</td>\n      <td>Happy Mothers Day  All my love</td>\n      <td>happi mother day all love</td>\n    </tr>\n    <tr>\n      <th>39997</th>\n      <td>1753919005</td>\n      <td>love</td>\n      <td>Happy Mother's Day to all the mommies out ther...</td>\n      <td>happi mother day mommi woman man long your mom...</td>\n    </tr>\n    <tr>\n      <th>39998</th>\n      <td>1753919043</td>\n      <td>happiness</td>\n      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n      <td>wassup beauti follow me peep out my new hit si...</td>\n    </tr>\n    <tr>\n      <th>39999</th>\n      <td>1753919049</td>\n      <td>love</td>\n      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n      <td>bullet train tokyo gf visit japan sinc thursda...</td>\n    </tr>\n  </tbody>\n</table>\n<p>40000 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "function which vectorize text and give the train and test data back"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def SpacyVec_data_from_df(df_input):\n",
    "    df = df_input\n",
    "    df['text_tokenized'] = df.clened_content.apply(lambda x: nlp_lg(x)) # tokenizing every text in the dataframe\n",
    "\n",
    "    df.sentiment = pd.Categorical(df.sentiment) # changing type of a column to categorical\n",
    "    df['Numeric_Labels'] = df.sentiment.cat.codes # saving category codes of column labels to new column\n",
    "\n",
    "    #doing sentence embedding before splitting, because the order makes no difference\n",
    "    df['text_vectorized'] = df['text_tokenized'].apply(lambda x: x.vector)\n",
    "\n",
    "    # splitting data _________________COULD BE CHANGED____________________________________________________\n",
    "    data_train, data_test, label_train, label_test = train_test_split(df.text_vectorized, df.Numeric_Labels,\n",
    "                                                                 test_size=0.30,\n",
    "                                                                 random_state=101, shuffle=True)\n",
    "   # __________________________________________________________________________________________________________\n",
    "\n",
    "    # appending all array rows into one and reshaping them from (1,300) shape to (300,1) shape\n",
    "    data_list_train = [vec.reshape(1,-1) for vec in data_train]\n",
    "    data_list_test = [vec.reshape(1,-1) for vec in data_test]\n",
    "\n",
    "    # concentrating array to get them readable by sklearn models\n",
    "    data_train_reshaped = np.concatenate(data_list_train)\n",
    "    data_test_reshaped = np.concatenate(data_list_test)\n",
    "\n",
    "    return data_train_reshaped, data_test_reshaped, label_train, label_test\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "def TfIdf_data_from_df(df_input):\n",
    "    df = df_input\n",
    "    df.sentiment = pd.Categorical(df.sentiment) # changing type of a column to categorical\n",
    "    df['Numeric_Labels'] = df.sentiment.cat.codes # saving category codes of column labels to new column\n",
    "\n",
    "    # splitting data _________________COULD BE CHANGED____________________________________________________\n",
    "    data_train, data_test, label_train, label_test = train_test_split(df.cleaned_content, df.Numeric_Labels, test_size=0.30, random_state=101, shuffle=True)\n",
    "   # __________________________________________________________________________________________________________\n",
    "\n",
    "   # vectorizing test and train data with Tfidf\n",
    "    polarity_tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    polarity_bow_matrix_train = polarity_tfidf_vectorizer.fit_transform(data_train)\n",
    "    polarity_bow_matrix_test = polarity_tfidf_vectorizer.transform(data_test)\n",
    "\n",
    "\n",
    "    return polarity_bow_matrix_train, polarity_bow_matrix_test, label_train, label_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "data_train, data_test, label_train, label_test = TfIdf_data_from_df(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "forest_classifier = RandomForestClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate MLPClassifier:\n",
      "\n",
      "Accuracy: 0.330\n",
      "\n",
      "Confusion Matrix: \n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[[11966,     0],\n        [   34,     0]],\n\n       [[11946,     4],\n        [   50,     0]],\n\n       [[11704,    33],\n        [  261,     2]],\n\n       [[11775,    13],\n        [  212,     0]],\n\n       [[11390,    81],\n        [  513,    16]],\n\n       [[ 9408,  1001],\n        [ 1109,   482]],\n\n       [[11519,    86],\n        [  341,    54]],\n\n       [[10323,   589],\n        [  684,   404]],\n\n       [[ 6056,  3322],\n        [ 1055,  1567]],\n\n       [[11442,    69],\n        [  471,    18]],\n\n       [[ 9867,   517],\n        [ 1292,   324]],\n\n       [[11250,   122],\n        [  600,    28]],\n\n       [[ 7316,  2201],\n        [ 1416,  1067]]])"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_classifier = RandomForestClassifier()\n",
    "forest_classifier.fit(data_train, label_train)\n",
    "test_forest= forest_classifier.predict(data_test)\n",
    "\n",
    "#evaluationg model and reporting accuracy and multi-class confusion matrix\n",
    "print('\\nEvaluate MLPClassifier:')\n",
    "print('\\nAccuracy: %.3f' % metrics.accuracy_score(label_test, test_forest))\n",
    "print('\\nConfusion Matrix: ')\n",
    "multilabel_confusion_matrix(label_test, test_forest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f31c1fe1c36aaa4d32cb0816fd78552f0caa11e77dcf57aa2899123b61a94662"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}