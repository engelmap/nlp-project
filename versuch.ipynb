{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from string import digits\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import spacy\n",
    "en_core = spacy.load('en_core_web_sm')\n",
    "nlp_lg = spacy.load('en_core_web_lg')\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#binary\n",
    "data = pd.read_csv(\"tweet_emotions.csv\")\n",
    "count = 0\n",
    "for index, sent in enumerate(data.sentiment):\n",
    "    if sent == \"fun\" or sent == \"enthusiasm\" or sent == \"love\" or sent == \"happiness\" or sent ==\"relief\":\n",
    "        data.loc[index,['sentiment']] = \"positive\"\n",
    "    elif sent == \"hate\" or sent == \"anger\" or sent == \"empty\" or sent == \"worry\" or sent == \"sadness\" or sent == \"boredom\":\n",
    "        data.loc[index,['sentiment']] = \"negative\"\n",
    "    else:\n",
    "        #if count % 6 != 0:\n",
    "        data.drop([index], axis=0, inplace=True)\n",
    "\n",
    "data.to_csv('tweet_emotions_binary.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data\n",
    "data['sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#three classes\n",
    "data = pd.read_csv(\"tweet_emotions.csv\")\n",
    "count = 0\n",
    "for index, sent in enumerate(data.sentiment):\n",
    "    if sent == \"fun\" or sent == \"enthusiasm\" or sent == \"love\" or sent == \"happiness\" or sent ==\"relief\":\n",
    "        data.loc[index,['sentiment']] = \"positive\"\n",
    "    elif sent == \"hate\" or sent == \"anger\" or sent == \"empty\" or sent == \"worry\" or sent == \"sadness\" or sent == \"boredom\":\n",
    "        data.loc[index,['sentiment']] = \"negative\"\n",
    "    elif sent == \"surprise\":\n",
    "        data.drop([index], axis=0, inplace=True)\n",
    "data.to_csv('tweet_emotions_three_classes.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data\n",
    "data['sentiment'].value_counts()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data cleaning functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def remove_punctuation(line_text):\n",
    "    line_text_without_punct = re.sub(r'[^\\w\\s]', '', line_text)\n",
    "    return line_text_without_punct\n",
    "\n",
    "\n",
    "def remove_numbers(line_text):\n",
    "    table = str.maketrans('', '', digits)\n",
    "    line_text_without_nums = line_text.translate(table)\n",
    "    return line_text_without_nums\n",
    "\n",
    "def remove_url(line_text):\n",
    "    #(https?:\\/\\/) matches http:// or https://\n",
    "    #(\\s)* optional whitespaces\n",
    "    #(www\\.)? optionally matches www.\n",
    "    # (\\s)* optionally matches whitespaces\n",
    "    #'((\\w|\\s)+\\.)* matches 0 or more of one or more word characters followed by a period\n",
    "    #([\\w\\-\\s]+\\/)* matches 0 or more of one or more words(or a dash or a space) followed by '\\'\n",
    "    #([\\w\\-]+) any remaining path at the end of the url followed by an optional ending\n",
    "    #((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)* matches ending query params (even with white spaces,etc)\n",
    "\n",
    "    line_text_without_url = re.sub(r'(https?:\\/\\/)(\\s)*(www\\.)?(\\s)*((\\w|\\s)+\\.)*([\\w\\-\\s]+\\/)*([\\w\\-]+)((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)*', '', line_text)\n",
    "    return line_text_without_url\n",
    "\n",
    "def remove_username(line_text):\n",
    "    line_text_without_username = re.sub(\"([@#][A-Za-z0-9_]+)|(\\w+:\\/\\/\\S+)\",'', line_text)\n",
    "    return line_text_without_username\n",
    "\n",
    "def remove_stopwords(line_text):\n",
    "    line_text_without_stopwords = ' '.join([word for word in line_text.split()\n",
    "                                           if word not in (stopwords.words('english'))])\n",
    "    return line_text_without_stopwords\n",
    "\n",
    "def translate_abbreviations(line_text):\n",
    "    text_list = line_text.split()\n",
    "    with open(\"slang_abbreviations.txt\", 'r') as my_csv_file:\n",
    "        data_from_file = csv.reader(my_csv_file, delimiter=\"=\")\n",
    "        for index, _str in enumerate(text_list):\n",
    "            _str = re.sub('[^a-zA-Z0-9-_.]', '', _str)\n",
    "            for row in data_from_file:\n",
    "                if _str.upper() == row[0]:\n",
    "                    text_list[index] = row[1]\n",
    "    final_string = ' '.join(text_list)\n",
    "    return final_string\n",
    "\n",
    "def remove_hashtags(line_text):\n",
    "    line_text_without_hashtags = line_text.replace('#','')\n",
    "    return line_text_without_hashtags\n",
    "\n",
    "def lemmatizing(line_text):\n",
    "    final_string = \" \".join([word.lemma_ for word in en_core(line_text)])\n",
    "    return final_string\n",
    "\n",
    "def clean_line(line_text):\n",
    "    text_zero = remove_numbers(line_text)\n",
    "    text_one = remove_username(text_zero)\n",
    "    text_two = remove_url(text_one)\n",
    "    text_three = remove_punctuation(text_two)\n",
    "    text_four = remove_hashtags(text_three)\n",
    "    text_five = remove_stopwords(text_four)\n",
    "    text_six = translate_abbreviations(text_five)\n",
    "    text_final = lemmatizing(text_six)\n",
    "    return text_final.lower()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cleaning the text and saving cleaned version to new column 'cleaned_content'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_multiple = pd.read_csv(\"tweet_emotions.csv\")\n",
    "df_binary = pd.read_csv(\"tweet_emotions_binary.csv\")\n",
    "df_three_classes = pd.read_csv(\"tweet_emotions_three_classes.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_multiple['cleaned_content'] = df_multiple.content.apply(clean_line)\n",
    "df_binary['cleaned_content'] = df_binary.content.apply(clean_line)\n",
    "df_three_classes['cleaned_content'] = df_three_classes.content.apply(clean_line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Saving cleaned Dataframe to scv for future"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_binary.to_csv('tweet_emotions_binary_cleaned.csv')\n",
    "df_three_classes.to_csv('tweet_emotions_three_classes_cleaned.csv')\n",
    "df_multiple.to_csv('tweet_emotions_cleaned.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "function which vectorize text and give the train and test data back"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def SpacyVec_data_from_df(df_input):\n",
    "    df = df_input\n",
    "    df['text_tokenized'] = df.clened_content.apply(lambda x: nlp_lg(x)) # tokenizing every text in the dataframe\n",
    "\n",
    "    df.sentiment = pd.Categorical(df.sentiment) # changing type of a column to categorical\n",
    "    df['Numeric_Labels'] = df.sentiment.cat.codes # saving category codes of column labels to new column\n",
    "\n",
    "    #doing sentence embedding before splitting, because the order makes no difference\n",
    "    df['text_vectorized'] = df['text_tokenized'].apply(lambda x: x.vector)\n",
    "\n",
    "    # splitting data _________________COULD BE CHANGED____________________________________________________\n",
    "    data_train, data_test, label_train, label_test = train_test_split(df.text_vectorized, df.Numeric_Labels,\n",
    "                                                                 test_size=0.30,\n",
    "                                                                 random_state=101, shuffle=True)\n",
    "   # __________________________________________________________________________________________________________\n",
    "\n",
    "    # appending all array rows into one and reshaping them from (1,300) shape to (300,1) shape\n",
    "    data_list_train = [vec.reshape(1,-1) for vec in data_train]\n",
    "    data_list_test = [vec.reshape(1,-1) for vec in data_test]\n",
    "\n",
    "    # concentrating array to get them readable by sklearn models\n",
    "    data_train_reshaped = np.concatenate(data_list_train)\n",
    "    data_test_reshaped = np.concatenate(data_list_test)\n",
    "\n",
    "    return data_train_reshaped, data_test_reshaped, label_train, label_test\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def TfIdf_data_from_df(df_input):\n",
    "    df = df_input\n",
    "    df.sentiment = pd.Categorical(df.sentiment) # changing type of a column to categorical\n",
    "    df['Numeric_Labels'] = df.sentiment.cat.codes # saving category codes of column labels to new column\n",
    "\n",
    "    # splitting data _________________COULD BE CHANGED____________________________________________________\n",
    "    data_train, data_test, label_train, label_test = train_test_split(df.cleaned_content, df.Numeric_Labels, test_size=0.30, random_state=101, shuffle=True)\n",
    "   # __________________________________________________________________________________________________________\n",
    "\n",
    "   # vectorizing test and train data with Tfidf\n",
    "    polarity_tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    polarity_bow_matrix_train = polarity_tfidf_vectorizer.fit_transform(data_train)\n",
    "    polarity_bow_matrix_test = polarity_tfidf_vectorizer.transform(data_test)\n",
    "\n",
    "\n",
    "    return polarity_bow_matrix_train, polarity_bow_matrix_test, label_train, label_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_binary = pd.read_csv('tweet_emotions_binary_cleaned.csv')\n",
    "data_train, data_test, label_train, label_test = TfIdf_data_from_df(df_binary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forest_classifier = RandomForestClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forest_classifier = RandomForestClassifier()\n",
    "forest_classifier.fit(data_train, label_train)\n",
    "test_forest= forest_classifier.predict(data_test)\n",
    "\n",
    "#evaluationg model and reporting accuracy and multi-class confusion matrix\n",
    "print('\\nEvaluate MLPClassifier:')\n",
    "print('\\nAccuracy: %.3f' % metrics.accuracy_score(label_test, test_forest))\n",
    "print('\\nConfusion Matrix: ')\n",
    "multilabel_confusion_matrix(label_test, test_forest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_models(df, vectorizer, text=\"text\", labels=\"emotion\"):\n",
    "    classifiers = [svm.LinearSVC(), RandomForestClassifier()] #DecisionTreeClassifier()]# # MLPClassifier()]\n",
    "\n",
    "    #look into learning curves (do we have enough samples?) / validation curves (is the model under/overfitting?)\n",
    "\n",
    "    X = vect.transform(df[text])\n",
    "    y = df[labels]\n",
    "\n",
    "    print(\"Amount of features: \", len(vect.get_feature_names_out()))\n",
    "    print(\"Features: \", vect.get_feature_names_out())\n",
    "\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    plot_learning_curve(classifiers, X, y, ylim=(0.5, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "    results = calc_metrics(classifiers, X, y)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "\n",
    "    plt.show("
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_models(df, vectorizer, text=\"text\", labels=\"emotion\"):\n",
    "    classifiers = [svm.LinearSVC(), RandomForestClassifier()] #DecisionTreeClassifier()]# # MLPClassifier()]\n",
    "\n",
    "    #look into learning curves (do we have enough samples?) / validation curves (is the model under/overfitting?)\n",
    "\n",
    "    X = vect.transform(df[text])\n",
    "    y = df[labels]\n",
    "\n",
    "    print(\"Amount of features: \", len(vect.get_feature_names_out()))\n",
    "    print(\"Features: \", vect.get_feature_names_out())\n",
    "\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    plot_learning_curve(classifiers, X, y, ylim=(0.5, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "    results = calc_metrics(classifiers, X, y)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "\n",
    "    plt.show("
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f31c1fe1c36aaa4d32cb0816fd78552f0caa11e77dcf57aa2899123b61a94662"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}