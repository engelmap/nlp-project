{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dmitry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from string import digits\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import spacy\n",
    "en_core = spacy.load('en_core_web_sm')\n",
    "nlp_lg = spacy.load('en_core_web_lg')\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#binary\n",
    "data = pd.read_csv(\"tweet_emotions.csv\")\n",
    "count = 0\n",
    "for index, sent in enumerate(data.sentiment):\n",
    "    if sent == \"fun\" or sent == \"enthusiasm\" or sent == \"love\" or sent == \"happiness\" or sent ==\"relief\":\n",
    "        data.loc[index,['sentiment']] = \"positive\"\n",
    "    elif sent == \"hate\" or sent == \"anger\" or sent == \"empty\" or sent == \"worry\" or sent == \"sadness\" or sent == \"boredom\":\n",
    "        data.loc[index,['sentiment']] = \"negative\"\n",
    "    else:\n",
    "        #if count % 6 != 0:\n",
    "        data.drop([index], axis=0, inplace=True)\n",
    "\n",
    "data.to_csv('tweet_emotions_binary.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data\n",
    "data['sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#three classes\n",
    "data = pd.read_csv(\"tweet_emotions.csv\")\n",
    "count = 0\n",
    "for index, sent in enumerate(data.sentiment):\n",
    "    if sent == \"fun\" or sent == \"enthusiasm\" or sent == \"love\" or sent == \"happiness\" or sent ==\"relief\":\n",
    "        data.loc[index,['sentiment']] = \"positive\"\n",
    "    elif sent == \"hate\" or sent == \"anger\" or sent == \"empty\" or sent == \"worry\" or sent == \"sadness\" or sent == \"boredom\":\n",
    "        data.loc[index,['sentiment']] = \"negative\"\n",
    "    elif sent == \"surprise\":\n",
    "        data.drop([index], axis=0, inplace=True)\n",
    "data.to_csv('tweet_emotions_three_classes.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data\n",
    "data['sentiment'].value_counts()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data cleaning functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "def remove_punctuation(line_text):\n",
    "    line_text_without_punct = re.sub(r'[^\\w\\s]', '', line_text)\n",
    "    return line_text_without_punct\n",
    "\n",
    "\n",
    "def remove_numbers(line_text):\n",
    "    table = str.maketrans('', '', digits)\n",
    "    line_text_without_nums = line_text.translate(table)\n",
    "    return line_text_without_nums\n",
    "\n",
    "def remove_url(line_text):\n",
    "    #(https?:\\/\\/) matches http:// or https://\n",
    "    #(\\s)* optional whitespaces\n",
    "    #(www\\.)? optionally matches www.\n",
    "    # (\\s)* optionally matches whitespaces\n",
    "    #'((\\w|\\s)+\\.)* matches 0 or more of one or more word characters followed by a period\n",
    "    #([\\w\\-\\s]+\\/)* matches 0 or more of one or more words(or a dash or a space) followed by '\\'\n",
    "    #([\\w\\-]+) any remaining path at the end of the url followed by an optional ending\n",
    "    #((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)* matches ending query params (even with white spaces,etc)\n",
    "\n",
    "    line_text_without_url = re.sub(r'(https?:\\/\\/)(\\s)*(www\\.)?(\\s)*((\\w|\\s)+\\.)*([\\w\\-\\s]+\\/)*([\\w\\-]+)((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)*', '', line_text)\n",
    "    return line_text_without_url\n",
    "\n",
    "def remove_username(line_text):\n",
    "    line_text_without_username = re.sub(\"([@#][A-Za-z0-9_]+)|(\\w+:\\/\\/\\S+)\",'', line_text)\n",
    "    return line_text_without_username\n",
    "\n",
    "def remove_stopwords(line_text):\n",
    "    line_text_without_stopwords = ' '.join([word for word in line_text.split()\n",
    "                                           if word not in (stopwords.words('english'))])\n",
    "    return line_text_without_stopwords\n",
    "\n",
    "def translate_abbreviations(line_text):\n",
    "    text_list = line_text.split()\n",
    "    with open(\"slang_abbreviations.txt\", 'r') as my_csv_file:\n",
    "        data_from_file = csv.reader(my_csv_file, delimiter=\"=\")\n",
    "        for index, _str in enumerate(text_list):\n",
    "            _str = re.sub('[^a-zA-Z0-9-_.]', '', _str)\n",
    "            for row in data_from_file:\n",
    "                if _str.upper() == row[0]:\n",
    "                    text_list[index] = row[1]\n",
    "    final_string = ' '.join(text_list)\n",
    "    return final_string\n",
    "\n",
    "def remove_hashtags(line_text):\n",
    "    line_text_without_hashtags = line_text.replace('#','')\n",
    "    return line_text_without_hashtags\n",
    "\n",
    "def lemmatizing(line_text):\n",
    "    final_string = \" \".join([word.lemma_ for word in en_core(line_text)])\n",
    "    return final_string\n",
    "\n",
    "def clean_line(line_text):\n",
    "    text_zero = remove_numbers(line_text)\n",
    "    text_one = remove_username(text_zero)\n",
    "    text_two = remove_url(text_one)\n",
    "    text_three = remove_punctuation(text_two)\n",
    "    text_four = remove_hashtags(text_three)\n",
    "    text_five = remove_stopwords(text_four)\n",
    "    text_six = translate_abbreviations(text_five)\n",
    "    text_final = lemmatizing(text_six)\n",
    "    return text_final.lower()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "negative_dual = pd.read_csv(\"negative_dual.csv\")\n",
    "positive_dual = pd.read_csv(\"positive_dual.csv\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "negative_dual.columns = ['', 'tweet_id', 'sentiment', 'content']\n",
    "positive_dual.columns = ['', 'tweet_id', 'sentiment', 'content']\n",
    "for index, sent in enumerate(negative_dual.sentiment):\n",
    "    negative_dual.loc[index,['sentiment']] = \"negative\"\n",
    "for index, sent in enumerate(positive_dual.sentiment):\n",
    "    positive_dual.loc[index,['sentiment']] = \"positive\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                tweet_id sentiment  \\\n0          4  1956968416  positive   \n1         14  1956970860  positive   \n2         16  1956971170  positive   \n3         21  1956972097  positive   \n4         34  1956975927  positive   \n...      ...         ...       ...   \n16755  39941  1753903578  negative   \n16756  39956  1753903987  negative   \n16757  39965  1753904398  negative   \n16758  39975  1753904682  negative   \n16759  39978  1753904868  negative   \n\n                                                 content  \n0      @dannycastillo We want to trade with someone w...  \n1                                           Got the news  \n2                                   @annarosekerr agreed  \n3      Wondering why I'm awake at 7am,writing a new s...  \n4                SoCal!  stoked. or maybe not.. tomorrow  \n...                                                  ...  \n16755  @PH7S sure. But be careful also of making stat...  \n16756                 How Do You Sleep - Jesse McCartney  \n16757                         is heading off to the fair  \n16758    @lexia Or even listen to Susan's green policies  \n16759  @givemestrength bloody Feds, they lost last st...  \n\n[33688 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>tweet_id</th>\n      <th>sentiment</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>1956968416</td>\n      <td>positive</td>\n      <td>@dannycastillo We want to trade with someone w...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14</td>\n      <td>1956970860</td>\n      <td>positive</td>\n      <td>Got the news</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16</td>\n      <td>1956971170</td>\n      <td>positive</td>\n      <td>@annarosekerr agreed</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21</td>\n      <td>1956972097</td>\n      <td>positive</td>\n      <td>Wondering why I'm awake at 7am,writing a new s...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34</td>\n      <td>1956975927</td>\n      <td>positive</td>\n      <td>SoCal!  stoked. or maybe not.. tomorrow</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16755</th>\n      <td>39941</td>\n      <td>1753903578</td>\n      <td>negative</td>\n      <td>@PH7S sure. But be careful also of making stat...</td>\n    </tr>\n    <tr>\n      <th>16756</th>\n      <td>39956</td>\n      <td>1753903987</td>\n      <td>negative</td>\n      <td>How Do You Sleep - Jesse McCartney</td>\n    </tr>\n    <tr>\n      <th>16757</th>\n      <td>39965</td>\n      <td>1753904398</td>\n      <td>negative</td>\n      <td>is heading off to the fair</td>\n    </tr>\n    <tr>\n      <th>16758</th>\n      <td>39975</td>\n      <td>1753904682</td>\n      <td>negative</td>\n      <td>@lexia Or even listen to Susan's green policies</td>\n    </tr>\n    <tr>\n      <th>16759</th>\n      <td>39978</td>\n      <td>1753904868</td>\n      <td>negative</td>\n      <td>@givemestrength bloody Feds, they lost last st...</td>\n    </tr>\n  </tbody>\n</table>\n<p>33688 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary_new = pd.concat([positive_dual, negative_dual])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df_binary_new['cleaned_content'] = df_binary_new.content.apply(clean_line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df_binary_new.to_csv(\"tweet_emotions_binary.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cleaning the text and saving cleaned version to new column 'cleaned_content'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_multiple = pd.read_csv(\"tweet_emotions.csv\")\n",
    "df_binary = pd.read_csv(\"tweet_emotions_binary.csv\")\n",
    "df_three_classes = pd.read_csv(\"tweet_emotions_three_classes.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_multiple['cleaned_content'] = df_multiple.content.apply(clean_line)\n",
    "df_binary['cleaned_content'] = df_binary.content.apply(clean_line)\n",
    "df_three_classes['cleaned_content'] = df_three_classes.content.apply(clean_line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Saving cleaned Dataframe to scv for future"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_binary.to_csv('tweet_emotions_binary_cleaned.csv')\n",
    "df_three_classes.to_csv('tweet_emotions_three_classes_cleaned.csv')\n",
    "df_multiple.to_csv('tweet_emotions_cleaned.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "function which vectorize text and give the train and test data back"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def SpacyVec_data_from_df(df_input):\n",
    "    df = df_input\n",
    "    df['text_tokenized'] = df.clened_content.apply(lambda x: nlp_lg(x)) # tokenizing every text in the dataframe\n",
    "\n",
    "    df.sentiment = pd.Categorical(df.sentiment) # changing type of a column to categorical\n",
    "    df['Numeric_Labels'] = df.sentiment.cat.codes # saving category codes of column labels to new column\n",
    "\n",
    "    #doing sentence embedding before splitting, because the order makes no difference\n",
    "    df['text_vectorized'] = df['text_tokenized'].apply(lambda x: x.vector)\n",
    "\n",
    "    # splitting data _________________COULD BE CHANGED____________________________________________________\n",
    "    data_train, data_test, label_train, label_test = train_test_split(df.text_vectorized, df.Numeric_Labels,\n",
    "                                                                 test_size=0.30,\n",
    "                                                                 random_state=101, shuffle=True)\n",
    "   # __________________________________________________________________________________________________________\n",
    "\n",
    "    # appending all array rows into one and reshaping them from (1,300) shape to (300,1) shape\n",
    "    data_list_train = [vec.reshape(1,-1) for vec in data_train]\n",
    "    data_list_test = [vec.reshape(1,-1) for vec in data_test]\n",
    "\n",
    "    # concentrating array to get them readable by sklearn models\n",
    "    data_train_reshaped = np.concatenate(data_list_train)\n",
    "    data_test_reshaped = np.concatenate(data_list_test)\n",
    "\n",
    "    return data_train_reshaped, data_test_reshaped, label_train, label_test\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def TfIdf_data_from_df(df_input):\n",
    "    df = df_input\n",
    "    df.sentiment = pd.Categorical(df.sentiment) # changing type of a column to categorical\n",
    "    df['Numeric_Labels'] = df.sentiment.cat.codes # saving category codes of column labels to new column\n",
    "\n",
    "    # splitting data _________________COULD BE CHANGED____________________________________________________\n",
    "    data_train, data_test, label_train, label_test = train_test_split(df.cleaned_content, df.Numeric_Labels, test_size=0.30, random_state=101, shuffle=True)\n",
    "   # __________________________________________________________________________________________________________\n",
    "\n",
    "   # vectorizing test and train data with Tfidf\n",
    "    polarity_tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    polarity_bow_matrix_train = polarity_tfidf_vectorizer.fit_transform(data_train)\n",
    "    polarity_bow_matrix_test = polarity_tfidf_vectorizer.transform(data_test)\n",
    "\n",
    "\n",
    "    return polarity_bow_matrix_train, polarity_bow_matrix_test, label_train, label_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_binary = pd.read_csv('tweet_emotions_binary_cleaned.csv')\n",
    "data_train, data_test, label_train, label_test = TfIdf_data_from_df(df_binary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forest_classifier = RandomForestClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forest_classifier = RandomForestClassifier()\n",
    "forest_classifier.fit(data_train, label_train)\n",
    "test_forest= forest_classifier.predict(data_test)\n",
    "\n",
    "#evaluationg model and reporting accuracy and multi-class confusion matrix\n",
    "print('\\nEvaluate MLPClassifier:')\n",
    "print('\\nAccuracy: %.3f' % metrics.accuracy_score(label_test, test_forest))\n",
    "print('\\nConfusion Matrix: ')\n",
    "multilabel_confusion_matrix(label_test, test_forest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_models(df, vectorizer, text=\"text\", labels=\"emotion\"):\n",
    "    classifiers = [svm.LinearSVC(), RandomForestClassifier()] #DecisionTreeClassifier()]# # MLPClassifier()]\n",
    "\n",
    "    #look into learning curves (do we have enough samples?) / validation curves (is the model under/overfitting?)\n",
    "\n",
    "    X = vect.transform(df[text])\n",
    "    y = df[labels]\n",
    "\n",
    "    print(\"Amount of features: \", len(vect.get_feature_names_out()))\n",
    "    print(\"Features: \", vect.get_feature_names_out())\n",
    "\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    plot_learning_curve(classifiers, X, y, ylim=(0.5, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "    results = calc_metrics(classifiers, X, y)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "\n",
    "    plt.show("
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_models(df, vectorizer, text=\"text\", labels=\"emotion\"):\n",
    "    classifiers = [svm.LinearSVC(), RandomForestClassifier()] #DecisionTreeClassifier()]# # MLPClassifier()]\n",
    "\n",
    "    #look into learning curves (do we have enough samples?) / validation curves (is the model under/overfitting?)\n",
    "\n",
    "    X = vect.transform(df[text])\n",
    "    y = df[labels]\n",
    "\n",
    "    print(\"Amount of features: \", len(vect.get_feature_names_out()))\n",
    "    print(\"Features: \", vect.get_feature_names_out())\n",
    "\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    plot_learning_curve(classifiers, X, y, ylim=(0.5, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "    results = calc_metrics(classifiers, X, y)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "\n",
    "    plt.show("
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#binary\n",
    "data = pd.read_csv(\"tweet_emotions.csv\")\n",
    "count = 0\n",
    "for index, sent in enumerate(data.sentiment):\n",
    "    if sent == \"fun\" or sent == \"enthusiasm\" or sent == \"love\" or sent == \"happiness\" or sent ==\"relief\":\n",
    "        data.loc[index,['sentiment']] = \"positive\"\n",
    "    elif sent == \"hate\" or sent == \"anger\" or sent == \"empty\" or sent == \"worry\" or sent == \"sadness\" or sent == \"boredom\":\n",
    "        data.loc[index,['sentiment']] = \"negative\"\n",
    "    else:\n",
    "        #if count % 6 != 0:\n",
    "        data.drop([index], axis=0, inplace=True)\n",
    "\n",
    "data.to_csv('tweet_emotions_binary.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data\n",
    "data['sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#three classes\n",
    "data = pd.read_csv(\"tweet_emotions.csv\")\n",
    "count = 0\n",
    "for index, sent in enumerate(data.sentiment):\n",
    "    if sent == \"fun\" or sent == \"enthusiasm\" or sent == \"love\" or sent == \"happiness\" or sent ==\"relief\":\n",
    "        data.loc[index,['sentiment']] = \"positive\"\n",
    "    elif sent == \"hate\" or sent == \"anger\" or sent == \"empty\" or sent == \"worry\" or sent == \"sadness\" or sent == \"boredom\":\n",
    "        data.loc[index,['sentiment']] = \"negative\"\n",
    "    elif sent == \"surprise\":\n",
    "        data.drop([index], axis=0, inplace=True)\n",
    "data.to_csv('tweet_emotions_three_classes.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data\n",
    "data['sentiment'].value_counts()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data cleaning functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def remove_punctuation(line_text):\n",
    "    line_text_without_punct = re.sub(r'[^\\w\\s]', '', line_text)\n",
    "    return line_text_without_punct\n",
    "\n",
    "\n",
    "def remove_numbers(line_text):\n",
    "    table = str.maketrans('', '', digits)\n",
    "    line_text_without_nums = line_text.translate(table)\n",
    "    return line_text_without_nums\n",
    "\n",
    "def remove_url(line_text):\n",
    "    #(https?:\\/\\/) matches http:// or https://\n",
    "    #(\\s)* optional whitespaces\n",
    "    #(www\\.)? optionally matches www.\n",
    "    # (\\s)* optionally matches whitespaces\n",
    "    #'((\\w|\\s)+\\.)* matches 0 or more of one or more word characters followed by a period\n",
    "    #([\\w\\-\\s]+\\/)* matches 0 or more of one or more words(or a dash or a space) followed by '\\'\n",
    "    #([\\w\\-]+) any remaining path at the end of the url followed by an optional ending\n",
    "    #((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)* matches ending query params (even with white spaces,etc)\n",
    "\n",
    "    line_text_without_url = re.sub(r'(https?:\\/\\/)(\\s)*(www\\.)?(\\s)*((\\w|\\s)+\\.)*([\\w\\-\\s]+\\/)*([\\w\\-]+)((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)*', '', line_text)\n",
    "    return line_text_without_url\n",
    "\n",
    "def remove_username(line_text):\n",
    "    line_text_without_username = re.sub(\"([@#][A-Za-z0-9_]+)|(\\w+:\\/\\/\\S+)\",'', line_text)\n",
    "    return line_text_without_username\n",
    "\n",
    "def remove_stopwords(line_text):\n",
    "    line_text_without_stopwords = ' '.join([word for word in line_text.split()\n",
    "                                           if word not in (stopwords.words('english'))])\n",
    "    return line_text_without_stopwords\n",
    "\n",
    "def translate_abbreviations(line_text):\n",
    "    text_list = line_text.split()\n",
    "    with open(\"slang_abbreviations.txt\", 'r') as my_csv_file:\n",
    "        data_from_file = csv.reader(my_csv_file, delimiter=\"=\")\n",
    "        for index, _str in enumerate(text_list):\n",
    "            _str = re.sub('[^a-zA-Z0-9-_.]', '', _str)\n",
    "            for row in data_from_file:\n",
    "                if _str.upper() == row[0]:\n",
    "                    text_list[index] = row[1]\n",
    "    final_string = ' '.join(text_list)\n",
    "    return final_string\n",
    "\n",
    "def remove_hashtags(line_text):\n",
    "    line_text_without_hashtags = line_text.replace('#','')\n",
    "    return line_text_without_hashtags\n",
    "\n",
    "def lemmatizing(line_text):\n",
    "    final_string = \" \".join([word.lemma_ for word in en_core(line_text)])\n",
    "    return final_string\n",
    "\n",
    "def clean_line(line_text):\n",
    "    text_zero = remove_numbers(line_text)\n",
    "    text_one = remove_username(text_zero)\n",
    "    text_two = remove_url(text_one)\n",
    "    text_three = remove_punctuation(text_two)\n",
    "    text_four = remove_hashtags(text_three)\n",
    "    text_five = remove_stopwords(text_four)\n",
    "    text_six = translate_abbreviations(text_five)\n",
    "    text_final = lemmatizing(text_six)\n",
    "    return text_final.lower()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cleaning the text and saving cleaned version to new column 'cleaned_content'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_multiple = pd.read_csv(\"tweet_emotions.csv\")\n",
    "df_binary = pd.read_csv(\"tweet_emotions_binary.csv\")\n",
    "df_three_classes = pd.read_csv(\"tweet_emotions_three_classes.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_multiple['cleaned_content'] = df_multiple.content.apply(clean_line)\n",
    "df_binary['cleaned_content'] = df_binary.content.apply(clean_line)\n",
    "df_three_classes['cleaned_content'] = df_three_classes.content.apply(clean_line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Saving cleaned Dataframe to scv for future"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_binary.to_csv('tweet_emotions_binary_cleaned.csv')\n",
    "df_three_classes.to_csv('tweet_emotions_three_classes_cleaned.csv')\n",
    "df_multiple.to_csv('tweet_emotions_cleaned.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "function which vectorize text and give the train and test data back"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def SpacyVec_data_from_df(df_input):\n",
    "    df = df_input\n",
    "    df['text_tokenized'] = df.clened_content.apply(lambda x: nlp_lg(x)) # tokenizing every text in the dataframe\n",
    "\n",
    "    df.sentiment = pd.Categorical(df.sentiment) # changing type of a column to categorical\n",
    "    df['Numeric_Labels'] = df.sentiment.cat.codes # saving category codes of column labels to new column\n",
    "\n",
    "    #doing sentence embedding before splitting, because the order makes no difference\n",
    "    df['text_vectorized'] = df['text_tokenized'].apply(lambda x: x.vector)\n",
    "\n",
    "    # splitting data _________________COULD BE CHANGED____________________________________________________\n",
    "    data_train, data_test, label_train, label_test = train_test_split(df.text_vectorized, df.Numeric_Labels,\n",
    "                                                                 test_size=0.30,\n",
    "                                                                 random_state=101, shuffle=True)\n",
    "   # __________________________________________________________________________________________________________\n",
    "\n",
    "    # appending all array rows into one and reshaping them from (1,300) shape to (300,1) shape\n",
    "    data_list_train = [vec.reshape(1,-1) for vec in data_train]\n",
    "    data_list_test = [vec.reshape(1,-1) for vec in data_test]\n",
    "\n",
    "    # concentrating array to get them readable by sklearn models\n",
    "    data_train_reshaped = np.concatenate(data_list_train)\n",
    "    data_test_reshaped = np.concatenate(data_list_test)\n",
    "\n",
    "    return data_train_reshaped, data_test_reshaped, label_train, label_test\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def TfIdf_data_from_df(df_input):\n",
    "    df = df_input\n",
    "    df.sentiment = pd.Categorical(df.sentiment) # changing type of a column to categorical\n",
    "    df['Numeric_Labels'] = df.sentiment.cat.codes # saving category codes of column labels to new column\n",
    "\n",
    "    # splitting data _________________COULD BE CHANGED____________________________________________________\n",
    "    data_train, data_test, label_train, label_test = train_test_split(df.cleaned_content, df.Numeric_Labels, test_size=0.30, random_state=101, shuffle=True)\n",
    "   # __________________________________________________________________________________________________________\n",
    "\n",
    "   # vectorizing test and train data with Tfidf\n",
    "    polarity_tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    polarity_bow_matrix_train = polarity_tfidf_vectorizer.fit_transform(data_train)\n",
    "    polarity_bow_matrix_test = polarity_tfidf_vectorizer.transform(data_test)\n",
    "\n",
    "\n",
    "    return polarity_bow_matrix_train, polarity_bow_matrix_test, label_train, label_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_binary = pd.read_csv('tweet_emotions_binary_cleaned.csv')\n",
    "data_train, data_test, label_train, label_test = TfIdf_data_from_df(df_binary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forest_classifier = RandomForestClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forest_classifier = RandomForestClassifier()\n",
    "forest_classifier.fit(data_train, label_train)\n",
    "test_forest= forest_classifier.predict(data_test)\n",
    "\n",
    "#evaluationg model and reporting accuracy and multi-class confusion matrix\n",
    "print('\\nEvaluate MLPClassifier:')\n",
    "print('\\nAccuracy: %.3f' % metrics.accuracy_score(label_test, test_forest))\n",
    "print('\\nConfusion Matrix: ')\n",
    "multilabel_confusion_matrix(label_test, test_forest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_models(df, vectorizer, text=\"text\", labels=\"emotion\"):\n",
    "    classifiers = [svm.LinearSVC(), RandomForestClassifier()] #DecisionTreeClassifier()]# # MLPClassifier()]\n",
    "\n",
    "    #look into learning curves (do we have enough samples?) / validation curves (is the model under/overfitting?)\n",
    "\n",
    "    X = vect.transform(df[text])\n",
    "    y = df[labels]\n",
    "\n",
    "    print(\"Amount of features: \", len(vect.get_feature_names_out()))\n",
    "    print(\"Features: \", vect.get_feature_names_out())\n",
    "\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    plot_learning_curve(classifiers, X, y, ylim=(0.5, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "    results = calc_metrics(classifiers, X, y)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "\n",
    "    plt.show("
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_models(df, vectorizer, text=\"text\", labels=\"emotion\"):\n",
    "    classifiers = [svm.LinearSVC(), RandomForestClassifier()] #DecisionTreeClassifier()]# # MLPClassifier()]\n",
    "\n",
    "    #look into learning curves (do we have enough samples?) / validation curves (is the model under/overfitting?)\n",
    "\n",
    "    X = vect.transform(df[text])\n",
    "    y = df[labels]\n",
    "\n",
    "    print(\"Amount of features: \", len(vect.get_feature_names_out()))\n",
    "    print(\"Features: \", vect.get_feature_names_out())\n",
    "\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    plot_learning_curve(classifiers, X, y, ylim=(0.5, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "    results = calc_metrics(classifiers, X, y)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "\n",
    "    plt.show("
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f31c1fe1c36aaa4d32cb0816fd78552f0caa11e77dcf57aa2899123b61a94662"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}